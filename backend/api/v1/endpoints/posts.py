"""Post management endpoints."""

from datetime import datetime
from typing import Any, Dict, List, Optional

from fastapi import APIRouter, Depends, HTTPException, Query, status
from pydantic import BaseModel, Field
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import selectinload

from db.session import get_db
from models import Post
from schemas.content_detection import ContentDetectionRequest, ContentDetectionResponse
from services.content_detection_service import ContentDetectionService
from services.post_media_service import PostMediaService
from utils.logging import get_logger


class PostResponse(BaseModel):
    """Response for a single post."""

    id: str = Field(..., description="Internal database ID")
    post_id: str = Field(..., description="Facebook post ID")
    content: str = Field(..., description="Post content")
    author: Optional[str] = Field(None, description="Post author")
    verdict: str = Field(..., description="AI detection verdict")
    confidence: float = Field(..., description="Confidence score")
    explanation: Optional[str] = Field(None, description="Verdict explanation")
    post_metadata: Optional[Dict[str, Any]] = Field(None, description="Additional metadata")
    created_at: datetime = Field(..., description="Creation timestamp")
    updated_at: datetime = Field(..., description="Last update timestamp")

    class Config:
        orm_mode = True
        from_attributes = True


class PostsListResponse(BaseModel):
    """Response for listing posts."""

    posts: List[PostResponse] = Field(..., description="List of posts")
    total: int = Field(..., description="Total number of posts matching filters")
    limit: int = Field(..., description="Number of posts per page")
    offset: int = Field(..., description="Number of posts skipped")


class PostUpdate(BaseModel):
    """Request for updating a post."""

    verdict: Optional[str] = Field(None, description="New verdict")
    confidence: Optional[float] = Field(None, ge=0.0, le=1.0, description="New confidence score")
    explanation: Optional[str] = Field(None, description="New explanation")
    author: Optional[str] = Field(None, description="Post author")
    metadata: Optional[Dict[str, Any]] = Field(None, description="Additional metadata")


logger = get_logger(__name__)

router = APIRouter(tags=["posts"])

# Initialize services
detection_service = ContentDetectionService()
post_media_service = PostMediaService()


@router.post("/process", response_model=ContentDetectionResponse)
async def process_post(
    request: ContentDetectionRequest,
    db: AsyncSession = Depends(get_db),
) -> ContentDetectionResponse:
    """
    Process a post for AI content detection.

    This endpoint analyzes text content, images, and videos to determine whether
    the content was likely generated by AI, created by humans, or uncertain.
    It performs all detection and processing for a post in one call.

    Supports simultaneous analysis of:
    - Text content (always analyzed)
    - Image URLs (analyzed if provided)
    - Video URLs (analyzed if provided)

    The results are stored in the database for future reference.
    """
    try:
        # Debug logging to see what's received
        logger.info(
            "Processing post detection request",
            post_id=request.post_id,
            content_length=len(request.content),
            image_count=len(request.image_urls or []),
            video_count=len(request.video_urls or []),
            author=request.author,
        )

        # Step 1: Save post and download/upload media to Gemini
        # This completes ALL media operations before proceeding
        logger.info("Step 1: Saving post and processing media", post_id=request.post_id)
        post = await post_media_service.save_post_before_detection(request, db)
        
        # Step 2: Wait a moment to ensure all files are written to disk
        import asyncio
        await asyncio.sleep(0.5)  # Small delay to ensure file system operations complete
        
        # Step 3: Run detection only after media is fully processed
        logger.info("Step 2: Running detection with downloaded media", post_id=request.post_id)
        result = await detection_service.detect(request, db)

        # Check if this was a cached result to avoid confusing logs
        is_cached = hasattr(result, "debug_info") and result.debug_info and result.debug_info.get("from_cache", False)

        if is_cached:
            # For cached results, just log that we returned cached data
            logger.info(
                "Returned cached detection result",
                post_id=request.post_id,
                verdict=result.verdict,
                confidence=round(result.confidence, 3),
                source="cache",
            )
        else:
            # For new analysis, update post with detection results and log processing
            post = await post_media_service.update_post_with_results(request.post_id, result, db)

            logger.info(
                "Post processing completed",
                post_id=request.post_id,
                verdict=result.verdict,
                confidence=round(result.confidence, 3),
                text_ai_probability=result.text_ai_probability,
                image_ai_probability=result.image_ai_probability,
                video_ai_probability=result.video_ai_probability,
                has_images=bool(result.image_analysis),
                has_videos=bool(result.video_analysis),
                source="new_analysis",
            )

        return result

    except Exception as e:
        logger.error("Error processing post", post_id=request.post_id, error=str(e), exc_info=True)
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to process post: {str(e)}")


@router.get("/{post_id}", response_model=PostResponse)
async def get_post(
    post_id: str,
    include_chats: bool = Query(False, description="Include chat history"),
    db: AsyncSession = Depends(get_db),
) -> PostResponse:
    """
    Get a specific post by Facebook post ID.

    Returns the post details including AI detection analysis results.
    Optionally includes chat history if requested.
    """
    try:
        query = select(Post).where(Post.post_id == post_id)

        if include_chats:
            query = query.options(selectinload(Post.chats))

        result = await db.execute(query)
        post = result.scalar_one_or_none()

        if not post:
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f"Post with ID {post_id} not found")

        return PostResponse.from_orm(post)

    except HTTPException:
        raise
    except Exception as e:
        logger.error("Error getting post", post_id=post_id, error=str(e), exc_info=True)
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to get post: {str(e)}")


@router.get("", response_model=PostsListResponse)
async def list_posts(
    verdict: Optional[str] = Query(None, description="Filter by verdict (ai_slop, human_content, uncertain)"),
    author: Optional[str] = Query(None, description="Filter by author"),
    min_confidence: Optional[float] = Query(None, ge=0.0, le=1.0, description="Minimum confidence"),
    max_confidence: Optional[float] = Query(None, ge=0.0, le=1.0, description="Maximum confidence"),
    limit: int = Query(10, ge=1, le=100, description="Number of posts to return"),
    offset: int = Query(0, ge=0, description="Number of posts to skip"),
    db: AsyncSession = Depends(get_db),
) -> PostsListResponse:
    """
    List posts with optional filters.

    Returns a paginated list of posts with their AI detection analysis results.
    Supports filtering by verdict, author, and confidence levels.
    """
    try:
        query = select(Post)

        # Apply filters
        if verdict:
            query = query.where(Post.verdict == verdict)
        if author:
            query = query.where(Post.author == author)
        if min_confidence is not None:
            query = query.where(Post.confidence >= min_confidence)
        if max_confidence is not None:
            query = query.where(Post.confidence <= max_confidence)

        # Order by creation date (newest first)
        query = query.order_by(Post.created_at.desc())

        # Apply pagination
        query = query.limit(limit).offset(offset)

        result = await db.execute(query)
        posts = result.scalars().all()

        # Get total count for pagination
        count_query = select(Post)
        if verdict:
            count_query = count_query.where(Post.verdict == verdict)
        if author:
            count_query = count_query.where(Post.author == author)
        if min_confidence is not None:
            count_query = count_query.where(Post.confidence >= min_confidence)
        if max_confidence is not None:
            count_query = count_query.where(Post.confidence <= max_confidence)

        count_result = await db.execute(count_query)
        total = len(count_result.scalars().all())

        return PostsListResponse(
            posts=[PostResponse.from_orm(post) for post in posts],
            total=total,
            limit=limit,
            offset=offset,
        )

    except Exception as e:
        logger.error("Error listing posts", verdict=verdict, limit=limit, offset=offset, error=str(e), exc_info=True)
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to list posts: {str(e)}")


@router.put("/{post_id}", response_model=PostResponse)
async def update_post(
    post_id: str,
    update: PostUpdate,
    db: AsyncSession = Depends(get_db),
) -> PostResponse:
    """
    Update a post's analysis results.

    Allows updating the verdict, confidence, and explanation for a post.
    This can be useful for manual corrections or re-analysis.
    """
    try:
        result = await db.execute(select(Post).where(Post.post_id == post_id))
        post = result.scalar_one_or_none()

        if not post:
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f"Post with ID {post_id} not found")

        # Update fields if provided
        if update.verdict is not None:
            post.verdict = update.verdict
        if update.confidence is not None:
            post.confidence = update.confidence
        if update.explanation is not None:
            post.explanation = update.explanation
        if update.author is not None:
            post.author = update.author
        if update.metadata is not None:
            post.post_metadata = update.metadata

        await db.commit()
        await db.refresh(post)

        logger.info("Post updated successfully", post_id=post_id, verdict=post.verdict, confidence=post.confidence)

        return PostResponse.from_orm(post)

    except HTTPException:
        raise
    except Exception as e:
        logger.error("Error updating post", post_id=post_id, error=str(e), exc_info=True)
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to update post: {str(e)}")


@router.delete("/{post_id}")
async def delete_post(
    post_id: str,
    db: AsyncSession = Depends(get_db),
) -> dict:
    """
    Delete a post and its associated data.

    Removes the post and all associated chat messages from the database.
    This action cannot be undone.
    """
    try:
        result = await db.execute(select(Post).where(Post.post_id == post_id))
        post = result.scalar_one_or_none()

        if not post:
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f"Post with ID {post_id} not found")

        await db.delete(post)
        await db.commit()

        logger.info("Post deleted successfully", post_id=post_id)

        return {"message": f"Post {post_id} deleted successfully"}

    except HTTPException:
        raise
    except Exception as e:
        logger.error("Error deleting post", post_id=post_id, error=str(e), exc_info=True)
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to delete post: {str(e)}")
